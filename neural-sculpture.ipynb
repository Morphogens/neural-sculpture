{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a918430d-2fae-46f4-9ff4-106551fed598",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24fc996-16c2-49df-b454-1cae1af18c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdf_clip import SDFCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5462e36c-ff26-4a59-82ca-d55543ff1250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClipLoss device cuda\n"
     ]
    }
   ],
   "source": [
    "sdf_clip = SDFCLIP(\n",
    "    prompt=\"Mesh of a bunny rabbit rendered with zbrush maya\",\n",
    "    out_img_width=256,\n",
    "    out_img_height=256,\n",
    "    use_single_cam=True,\n",
    "    is_jupyter=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a57cdb7-677d-460e-b0a6-ab425e4bbbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "image loss:  tensor(-16.4219, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "image weight:  tensor(65536)\n",
      "\n",
      "sdf loss:  tensor(0.2570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sdf weight:  tensor(512)\n",
      "\n",
      "lp loss:  tensor(0.5711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "lp weight:  tensor(512)\n",
      "\n",
      "loss:  tensor(-15.5938, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "STD: None\n",
      "\n",
      "AVG: tensor(-15.5905)\n",
      "\n",
      "sdf grid res: 8  - iteration: 4  -  cam view idx 0  -  cam iters: 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256 at 0x7F52393F37D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16487/2810609774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmax_std_res_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum_std_res_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmax_num_iters_per_camera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m~/neural-sculpture/sdf_clip.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, learning_rate, image_loss_weight, sdf_loss_weight, lp_loss_weight, max_std_res_loss, num_std_res_samples, max_num_iters_per_camera)\u001b[0m\n\u001b[1;32m    249\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                         \u001b[0mcam_view_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                         \u001b[0mcam_view_loss_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcam_view_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_view_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neural-sculpture/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neural-sculpture/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/neural-sculpture/lib/python3.7/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (16) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "sdf_grid = sdf_clip.run(\n",
    "    learning_rate = 0.03,\n",
    "    image_loss_weight = 1 / 1000,\n",
    "    sdf_loss_weight = 1 / 1000,\n",
    "    lp_loss_weight = 1 / 1000,\n",
    "    max_std_res_loss = 0.8,\n",
    "    num_std_res_samples = 3,\n",
    "    max_num_iters_per_camera = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c1d1f-e745-495e-aaa8-99f0a71b00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56b387-b414-4dfc-8085-704a2eb62d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae7991-ccd4-458b-a7ed-8127d7b6982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('bunny_grid.npy', sdf_grid.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724544d-6ab0-47e1-8f41-cf5f87d02678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from sdf_utils import generate_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebaeaa6-cc48-4abc-be41-3f113788b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "camera_angle_list = [\n",
    "    Tensor([0, 0, 5]),  # 0\n",
    "    Tensor([0.1, 5, 0]),\n",
    "    Tensor([5, 0, 0]),\n",
    "    Tensor([0, 0, -5]),\n",
    "    Tensor([0.1, -5, 0]),\n",
    "    Tensor([-5, 0, 0]),  # 5\n",
    "    Tensor([5 / math.sqrt(2), 0, 5 / math.sqrt(2)]),\n",
    "    Tensor([5 / math.sqrt(2), 5 / math.sqrt(2), 0]),\n",
    "    Tensor([0, 5 / math.sqrt(2), 5 / math.sqrt(2)]),\n",
    "    Tensor([-5 / math.sqrt(2), 0, -5 / math.sqrt(2)]),\n",
    "    Tensor([-5 / math.sqrt(2), -5 / math.sqrt(2), 0]),  #10\n",
    "    Tensor([0, -5 / math.sqrt(2), -5 / math.sqrt(2)]),\n",
    "    Tensor([-5 / math.sqrt(2), 0, 5 / math.sqrt(2)]),\n",
    "    Tensor([-5 / math.sqrt(2), 5 / math.sqrt(2), 0]),\n",
    "    Tensor([0, -5 / math.sqrt(2), 5 / math.sqrt(2)]),\n",
    "    Tensor([5 / math.sqrt(2), 0, -5 / math.sqrt(2)]),\n",
    "    Tensor([5 / math.sqrt(2), -5 / math.sqrt(2), 0]),\n",
    "    Tensor([0, 5 / math.sqrt(2), -5 / math.sqrt(2)]),\n",
    "    Tensor([5 / math.sqrt(3), 5 / math.sqrt(3), 5 / math.sqrt(3)]),\n",
    "    Tensor([5 / math.sqrt(3), 5 / math.sqrt(3), -5 / math.sqrt(3)]),\n",
    "    Tensor([5 / math.sqrt(3), -5 / math.sqrt(3), 5 / math.sqrt(3)]),\n",
    "    Tensor([-5 / math.sqrt(3), 5 / math.sqrt(3), 5 / math.sqrt(3)]),\n",
    "    Tensor([-5 / math.sqrt(3), -5 / math.sqrt(3), 5 / math.sqrt(3)]),\n",
    "    Tensor([-5 / math.sqrt(3), 5 / math.sqrt(3), -5 / math.sqrt(3)]),\n",
    "    Tensor([5 / math.sqrt(3), -5 / math.sqrt(3), -5 / math.sqrt(3)]),\n",
    "    Tensor([-5 / math.sqrt(3), -5 / math.sqrt(3), -5 / math.sqrt(3)])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f60c1-714b-4dae-8ad9-7e708eec47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cameras = 26\n",
    "camera_angle_list = [\n",
    "    torch.tensor([5 * math.cos(a), 0, 5 * math.sin(a)]).cuda()\n",
    "    for a in np.linspace(0, math.pi / 4, num_cameras)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e1f33-23dd-482e-b581-cdd194186ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box_min_x = -2.\n",
    "bounding_box_min_y = -2.\n",
    "bounding_box_min_z = -2.\n",
    "bounding_box_max_x = 2.\n",
    "bounding_box_max_y = 2.\n",
    "bounding_box_max_z = 2\n",
    "\n",
    "grid_res_x = grid_res_y = grid_res_z = sdf_grid.shape[0]\n",
    "voxel_size = torch.tensor([4. / (grid_res_x - 1)]).cuda()\n",
    "\n",
    "out_img_width = 512\n",
    "out_img_height = 512\n",
    "\n",
    "for cam in range(num_cameras):\n",
    "    image_initial = generate_image(\n",
    "        bounding_box_min_x,\n",
    "        bounding_box_min_y,\n",
    "        bounding_box_min_z,\n",
    "        bounding_box_max_x,\n",
    "        bounding_box_max_y,\n",
    "        bounding_box_max_z,\n",
    "        voxel_size,\n",
    "        grid_res_x,\n",
    "        grid_res_y,\n",
    "        grid_res_z,\n",
    "        out_img_width,\n",
    "        out_img_height,\n",
    "        sdf_grid,\n",
    "        camera_angle_list[cam],\n",
    "    )\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    image_initial_array = image_initial.detach().cpu().numpy() * 255\n",
    "    display(Image.fromarray(image_initial_array.astype(np.uint8)))\n",
    "    print(camera_angle_list[cam])\n",
    "    time.sleep(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8f58c-28e1-4a6f-8803-79eaa2c8ff37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28352c06-3130-4951-b2f0-e02532fd1ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
